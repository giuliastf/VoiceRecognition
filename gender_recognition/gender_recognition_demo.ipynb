{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57298233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giulia/Desktop/master/bd/proiect/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modele enhanced încărcate cu succes!\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "gmm_male_enh = joblib.load('gmm_male_enh.pkl')\n",
    "gmm_female_enh = joblib.load('gmm_female_enh.pkl')\n",
    "\n",
    "print(\"Modele enhanced încărcate cu succes!\")\n",
    "\n",
    "def extract_enhanced_features(audio):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std  = np.std(mfcc, axis=1)\n",
    "    \n",
    "    f0, voiced_flag, _ = librosa.pyin(\n",
    "        audio,\n",
    "        fmin=librosa.note_to_hz('C2'),\n",
    "        fmax=librosa.note_to_hz('C7'),\n",
    "        sr=16000,\n",
    "        frame_length=1024,\n",
    "        hop_length=256,\n",
    "        fill_na=np.nan\n",
    "    )\n",
    "    voiced_f0 = f0[voiced_flag & ~np.isnan(f0)]\n",
    "    pitch_mean = np.mean(voiced_f0) if len(voiced_f0) > 0 else 120.0\n",
    "    pitch_std  = np.std(voiced_f0) if len(voiced_f0) > 0 else 20.0\n",
    "    \n",
    "    return np.concatenate([mfcc_mean, mfcc_std, [pitch_mean, pitch_std]])\n",
    "\n",
    "def predict_gender(audio, sr=16000):\n",
    "    if sr != 16000:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "    \n",
    "    feat = extract_enhanced_features(audio)\n",
    "    score_m = gmm_male_enh.score(feat.reshape(1, -1))\n",
    "    score_f = gmm_female_enh.score(feat.reshape(1, -1))\n",
    "    \n",
    "    pred = 'female' if score_f > score_m else 'male'\n",
    "    confidence_proxy = abs(score_f - score_m)\n",
    "    \n",
    "    return {\n",
    "        'gender': pred,\n",
    "        'confidence_proxy': confidence_proxy,\n",
    "        'features_dim': len(feat)\n",
    "    }\n",
    "\n",
    "# Demo Gradio\n",
    "def gradio_predict(audio):\n",
    "    if audio is None:\n",
    "        return \"No audio received.\"\n",
    "    \n",
    "    sr, wav = audio\n",
    "    \n",
    "    if wav.dtype == np.int16:\n",
    "        wav = wav.astype(np.float32) / 32768.0\n",
    "    elif wav.dtype != np.float32:\n",
    "        wav = wav.astype(np.float32)\n",
    "    \n",
    "    if np.max(np.abs(wav)) > 0:\n",
    "        wav = wav / np.max(np.abs(wav))\n",
    "    \n",
    "    result = predict_gender(wav, sr)\n",
    "    return f\"Gender: **{result['gender'].upper()}**\\nConfidence proxy: {result['confidence_proxy']:.4f}\\nFeatures: {result['features_dim']}-dim\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=gradio_predict,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"], type=\"numpy\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Gender Recognition Live Demo - Giulia Stefania\",\n",
    "    description=\"Press 'Record', speak clearly for 3–5 seconds, then 'Stop'.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
